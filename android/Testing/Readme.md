# Hand Gesture Recognition using Deep Learning on Android

Name: Nandini Nerurkar

Institute: Dhirubhai Ambani Institute of Information and Communication Technology, Gandhinagar, Gujarat


## RETRAINING THE MODEL FOR YOUR DATA

Create a main folder named GestureImages.  Create 10 (or equal to the number of classes, whichever is applicable) subfolders named after the identified hand gestures and populate them with respective hand gesture images.  
Retrain the final layer of the Inception module using the instructions given in the following links:

Step 1:
https://hackernoon.com/creating-insanely-fast-image-classifiers-with-mobilenet-in-tensorflow-f030ce0a2991

Step 2:
https://hackernoon.com/building-an-insanely-fast-image-classifier-on-android-with-mobilenets-in-tensorflow-dc3e0c4410d4

For information on tuning hyperparameters while following the above steps refer to the link:
https://www.tensorflow.org/tutorials/image_retraining

## Running the tests

- ### CREATING EXCEL SHEET WITH TEST RESULTS

Create a new folder for TestingImages.  Create the subfolders for each class just like in the previous step and name each subfolder after a class.  Populate these folders with respective images.

Create a Microsoft Excel workbook with 10 (or equal to the number of classes, whichever is applicable) worksheets.  Name the worksheets after each of the 10 classes. In each worksheet, fill the cells B1, C1 and D1 with Filename, y_test, y_pred respectively in Bold letters.

The label_image3.py is a modified version of the label_image.py that comes with the Tensorflow for Poets master file. This modified version of the code accepts an entire directory of images and lists the output of the model in the Excel workbook that you have created.  

Make the following changes in label_image3.py:
On line 130, provide the path to the Excel workbook you have created.

Perform the following steps for each class:
1. On line 125, update the class_type variable 
2. In Anaconda Prompt, enter the folder where label_image3.py is located and run the following command:
	python label_image3.py --graph=<path/to/output/graph> --labels=<path/to/output/labels>  --image=<path/to/TestingImages/folder> --input_layer=input --output_layer=final_result --input_mean=128 --input_std=128 --input_width=224 --input_height=224


After following the above steps 10 times (or equal to the number of classes, whichever is applicable), each worksheet in the Excel workbook will have entries in the following format:
<Filename> <y_test> <y_pred>

Suppose the worksheet named "palm" is open.  Filename column has entries of all the images in TestingImages folder.  y_test column will be 1 if the image in the previous column is of a palm and 0 otherwise.  y_pred column has values belonging to the range [0,1].  This column lists the probability, calculated by the model, that the image is a palm.



- ### DERIVING GRAPHS FROM TEST RESULTS

Place the workbook in the same folder as the ipynb file.  Open the ipynb file using Jupyter Notebook. Make the following changes:
1. Update the file variable by entering the name of your workbook.
2. You can provide your own thresholds for deriving confusion matrices, within the range [0,1], for each class in the variable dict_thresholds.  
3. Alternatively, if you do not wish to provide your own thresholds comment this variable and uncomment one of the methods to derive thresholds. Also comment out the line- TH = dict_thresholds[class_type].
4. You can save the images of the graphs generated by uncommenting the statement- plt.savefig('<path/to/save/graphs/>'+'<graph type>'+class_type+'.png') and by  providing the path where you want to save your images.
5. Run all the cells in the Jupyter notebook sequentially.


